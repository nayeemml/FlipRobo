{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries and Webdrivers\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Importing the Chrome driver from the path and starting the browser\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "# Affixing the url\n",
    "url=\"https://www.naukri.com\"\n",
    "\n",
    "# In the opened Browser we are opening the necessary url by passing the url to the driver\n",
    "driver.get(url)\n",
    "\n",
    "# Finding the element to give the search input in the job field\n",
    "search_job=driver.find_element_by_name(\"keyword\")\n",
    "\n",
    "# Clearing the text before entering the necessary search parameter\n",
    "search_job.clear()\n",
    "\n",
    "# The search parameter that we are going to search here \"Data Analyst\" and sending the keys to the element \"keyword\"\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# Similarly we are finding the element by the name \"location\", clearing the search box and passing the value \"Bangalore\"\n",
    "search_location=driver.find_element_by_name(\"location\")\n",
    "search_location.clear()\n",
    "search_location.send_keys(\"Bangalore\")\n",
    "\n",
    "# Clicking the search button to execute the necessary search parameters\n",
    "driver.find_element_by_class_name(\"search-btn\").click()\n",
    "\n",
    "try:\n",
    "    myElem = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'fleft pages')))\n",
    "    print (\"Page is ready!\")\n",
    "except TimeoutException:\n",
    "    print (\"Loading took too much time!\")\n",
    "\n",
    "# Finding the titles of the jobs by passing the xpath values inthe title_tag\n",
    "title_tag=driver.find_elements_by_xpath(\"//div[@class='list']//article[@class='jobTuple bgWhite br4 mb-8']//div[@class='info fleft']//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "# Initialising the job Title holder\n",
    "job_title=[]\n",
    "\n",
    "# Running the for loop and limiting the title tag to first 10 locaitons\n",
    "for i in title_tag[0:10]:\n",
    "# Appending the title to Job_title\n",
    "    job_title.append(i.text)\n",
    "print(job_title)\n",
    "\n",
    "# Finding the location_tag field by passing the values in the xpath\n",
    "\n",
    "location_tag=driver.find_elements_by_xpath(\"//div[@class='info fleft']//ul[@class='mt-7']//li[@class='fleft grey-text br2 placeHolderLi location']//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "\n",
    "# Initialising the job_location field\n",
    "job_location=[]\n",
    "\n",
    "#Running the for loop of first 10 values of location_tag and appending the text in the job_location field company name field\n",
    "\n",
    "for i in location_tag[0:10]:\n",
    "    job_location.append(i.text)\n",
    "print(job_location)\n",
    "\n",
    "\n",
    "# Finding the company_tag field by passing the values in the xpath\n",
    "company_tag=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "# Initialising the company name field\n",
    "company_name=[]\n",
    "\n",
    "#Running the for loop to store the first 10 values of company tag in company name field\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "print(company_name)\n",
    "\n",
    "# Finding the experience tag by passing the xpath values\n",
    "experience_tag=driver.find_elements_by_xpath(\"//ul[@class='mt-7']//li[@class='fleft grey-text br2 placeHolderLi experience']//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "\n",
    "# Initialising the Experience Required field\n",
    "experience_required=[]\n",
    "\n",
    "#Running the for loop to store the first 10 values of experience tag in experience required field\n",
    "for i in experience_tag[0:10]:\n",
    "    experience_required.append(i.text)\n",
    "print(experience_required)\n",
    "\n",
    "# importing the pandas library to create a dataframe to store all the Data Analyst jobs available in \n",
    "# Bangalore in DataBangalore dataframe\n",
    "import pandas as pd\n",
    "DataAnalyst_Bangalore=pd.DataFrame({})\n",
    "\n",
    "DataAnalyst_Bangalore[\"Title\"]=job_title\n",
    "DataAnalyst_Bangalore[\"Location\"]=job_location\n",
    "DataAnalyst_Bangalore[\"Company Name\"]=company_name\n",
    "DataAnalyst_Bangalore[\"Experience\"]=experience_required\n",
    "DataAnalyst_Bangalore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries and Webdrivers\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Importing the Chrome driver from the path and starting the browser\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "# Affixing the url\n",
    "url=\"https://www.naukri.com\"\n",
    "\n",
    "# In the opened Browser we are opening the necessary url by passing the url to the driver\n",
    "driver.get(url)\n",
    "\n",
    "# Finding the element to give the search input in the job field\n",
    "search_job=driver.find_element_by_name(\"keyword\")\n",
    "\n",
    "# Clearing the text before entering the necessary search parameter\n",
    "search_job.clear()\n",
    "\n",
    "# The search parameter that we are going to search here \"Data Analyst\" and sending the keys to the element \"keyword\"\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# Similarly we are finding the element by the name \"location\", clearing the search box and passing the value \"Bangalore\"\n",
    "search_location=driver.find_element_by_name(\"location\")\n",
    "search_location.clear()\n",
    "search_location.send_keys(\"Bangalore\")\n",
    "\n",
    "# Clicking the search button to execute the necessary search parameters\n",
    "driver.find_element_by_class_name(\"search-btn\").click()\n",
    "\n",
    "try:\n",
    "    myElem = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'fleft pages')))\n",
    "    print (\"Page is ready!\")\n",
    "except TimeoutException:\n",
    "    print (\"Loading took too much time!\")\n",
    "    \n",
    "parentHandle = driver.window_handles[0]\n",
    "\n",
    "positions = driver.find_elements_by_xpath('//article[@class = \"jobTuple bgWhite br4 mb-8\"]')\n",
    "\n",
    "# Finding the titles of the jobs by passing the xpath values inthe title_tag\n",
    "title_tag=driver.find_elements_by_xpath(\"//div[@class='list']//article[@class='jobTuple bgWhite br4 mb-8']//div[@class='info fleft']//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "# Initialising the job Title holder\n",
    "job_title=[]\n",
    "\n",
    "# Running the for loop and limiting the title tag to first 10 locaitons\n",
    "for i in title_tag[0:10]:\n",
    "# Appending the title to Job_title\n",
    "    job_title.append(i.text)\n",
    "print(job_title)\n",
    "\n",
    "# Finding the location_tag field by passing the values in the xpath\n",
    "\n",
    "location_tag=driver.find_elements_by_xpath(\"//div[@class='info fleft']//ul[@class='mt-7']//li[@class='fleft grey-text br2 placeHolderLi location']//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "\n",
    "# Initialising the job_location field\n",
    "job_location=[]\n",
    "\n",
    "#Running the for loop of first 10 values of location_tag and appending the text in the job_location field company name field\n",
    "\n",
    "for i in location_tag[0:10]:\n",
    "    job_location.append(i.text)\n",
    "print(job_location)\n",
    "\n",
    "\n",
    "# Finding the company_tag field by passing the values in the xpath\n",
    "company_tag=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "# Initialising the company name field\n",
    "company_name=[]\n",
    "\n",
    "#Running the for loop to store the first 10 values of company tag in company name field\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "print(company_name)\n",
    "\n",
    "time.sleep(3)\n",
    "url=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/a\")\n",
    "urls=[]\n",
    "for i in url[0:10]:\n",
    "    urls.append(i.get_attribute('href'))\n",
    "# Since the length of description is showing 166 for now I have decided to just add the link to the description\n",
    "\n",
    "#     for i in urls:\n",
    "#         driver.get(i)\n",
    "#         time.sleep(3)\n",
    "#         desc=driver.find_elements_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[2]/div[1]/p\")\n",
    "#         for i in desc:\n",
    "#             full_desc.append(i.get_attribute(\"innerText\"))\n",
    "# urls\n",
    "\n",
    "# full_desc=[]\n",
    "# for i in urls:\n",
    "#     driver.get(i)\n",
    "#     time.sleep(3)\n",
    "#     desc=driver.find_elements_by_xpath(\"//*[@id='root']/main/div[2]/div[2]/section[2]/div[1]/p\")\n",
    "#     for i in desc:\n",
    "#         full_desc.append(i.get_attribute(\"innerText\"))\n",
    "# full_desc\n",
    "\n",
    "import pandas as pd\n",
    "DataScientist_Bangalore=pd.DataFrame({})\n",
    "\n",
    "DataScientist_Bangalore[\"Title\"]=job_title\n",
    "DataScientist_Bangalore[\"Location\"]=job_location\n",
    "DataScientist_Bangalore[\"Company Name\"]=company_name\n",
    "DataScientist_Bangalore[\"Description Link\"]=urls\n",
    "DataScientist_Bangalore\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "# You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "# You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "# The location filter to be used is “Delhi/NCR”\n",
    "# The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took too much time!\n",
      "['Data Scientist - Commercial Planning and Analysis', 'GCP Skilled Analytics Resources (Data engineer / Data scientists)', 'Data Scientist', 'Data Scientist Machine Learning', 'Business Analyst - Data Scientist', 'Analyst - Data Scientist', 'Only Fresher / Data Scientist / Data Analyst / Business Analytics- MNC', 'Data Scientist', 'Data Scientist', 'Data Analyst/Scientist']\n",
      "['Delhi NCR, Gurgaon', 'Pune, Bengaluru, Gurgaon', 'Gurgaon Gurugram', 'Gurgaon', 'Gurgaon', 'Gurgaon', 'Delhi NCR, Noida, Gurgaon', 'Gurgaon', 'Gurgaon', 'Gurgaon']\n",
      "['Air Asia India Limited', 'Aerial Telecom Solutions Pvt. Ltd.', 'IBM India Pvt. Limited', 'Delhivery', 'HyreFox Consultants Pvt Ltd', 'HyreFox Consultants Pvt Ltd', 'GABA Consultancy services', 'T & A Solutions', 'itForte Staffing Services Private Ltd.', 'itForte Staffing Services Private Ltd.']\n",
      "['1-6 Yrs', '3-8 Yrs', '3-5 Yrs', '1-3 Yrs', '3-5 Yrs', '1-3 Yrs', '0-0 Yrs', '1-6 Yrs', '3-8 Yrs', '3-7 Yrs']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Commercial Planning and Analysis</td>\n",
       "      <td>Delhi NCR, Gurgaon</td>\n",
       "      <td>Air Asia India Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GCP Skilled Analytics Resources (Data engineer...</td>\n",
       "      <td>Pune, Bengaluru, Gurgaon</td>\n",
       "      <td>Aerial Telecom Solutions Pvt. Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analyst - Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>T &amp; A Solutions</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>itForte Staffing Services Private Ltd.</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst/Scientist</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>itForte Staffing Services Private Ltd.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data Scientist - Commercial Planning and Analysis   \n",
       "1  GCP Skilled Analytics Resources (Data engineer...   \n",
       "2                                     Data Scientist   \n",
       "3                    Data Scientist Machine Learning   \n",
       "4                  Business Analyst - Data Scientist   \n",
       "5                           Analyst - Data Scientist   \n",
       "6  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                             Data Analyst/Scientist   \n",
       "\n",
       "                    Location                            Company Name  \\\n",
       "0         Delhi NCR, Gurgaon                  Air Asia India Limited   \n",
       "1   Pune, Bengaluru, Gurgaon      Aerial Telecom Solutions Pvt. Ltd.   \n",
       "2           Gurgaon Gurugram                  IBM India Pvt. Limited   \n",
       "3                    Gurgaon                               Delhivery   \n",
       "4                    Gurgaon             HyreFox Consultants Pvt Ltd   \n",
       "5                    Gurgaon             HyreFox Consultants Pvt Ltd   \n",
       "6  Delhi NCR, Noida, Gurgaon               GABA Consultancy services   \n",
       "7                    Gurgaon                         T & A Solutions   \n",
       "8                    Gurgaon  itForte Staffing Services Private Ltd.   \n",
       "9                    Gurgaon  itForte Staffing Services Private Ltd.   \n",
       "\n",
       "  Experience  \n",
       "0    1-6 Yrs  \n",
       "1    3-8 Yrs  \n",
       "2    3-5 Yrs  \n",
       "3    1-3 Yrs  \n",
       "4    3-5 Yrs  \n",
       "5    1-3 Yrs  \n",
       "6    0-0 Yrs  \n",
       "7    1-6 Yrs  \n",
       "8    3-8 Yrs  \n",
       "9    3-7 Yrs  "
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the necessary libraries and Webdrivers\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "# Importing the Chrome driver from the path and starting the browser\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "# Affixing the url\n",
    "url=\"https://www.naukri.com\"\n",
    "\n",
    "# In the opened Browser we are opening the necessary url by passing the url to the driver\n",
    "driver.get(url)\n",
    "\n",
    "# Finding the element to give the search input in the job field\n",
    "search_job=driver.find_element_by_name(\"keyword\")\n",
    "\n",
    "# Clearing the text before entering the necessary search parameter\n",
    "search_job.clear()\n",
    "\n",
    "# The search parameter that we are going to search here \"Data Analyst\" and sending the keys to the element \"keyword\"\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "time.sleep(3)\n",
    "\n",
    "# # Similarly we are finding the element by the name \"location\", clearing the search box and passing the value \"Bangalore\"\n",
    "search_location=driver.find_element_by_name(\"location\")\n",
    "search_location.clear()\n",
    "search_location.send_keys(\"Delhi/NCR\")\n",
    "\n",
    "# Clicking the search button to execute the necessary search parameters\n",
    "driver.find_element_by_class_name(\"search-btn\").click()\n",
    "\n",
    "try:\n",
    "    myElem = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.ID, 'fleft pages')))\n",
    "    print (\"Page is ready!\")\n",
    "except TimeoutException:\n",
    "    print (\"Loading took too much time!\")\n",
    "\n",
    "status= driver.find_element_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/i\").click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i\").click()\n",
    "\n",
    "\n",
    "time.sleep(5)\n",
    "# Finding the titles of the jobs by passing the xpath values inthe title_tag\n",
    "title_tag=driver.find_elements_by_xpath(\"//div[@class='list']//article[@class='jobTuple bgWhite br4 mb-8']//div[@class='info fleft']//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "# Initialising the job Title holder\n",
    "job_title=[]\n",
    "\n",
    "# Running the for loop and limiting the title tag to first 10 locaitons\n",
    "for i in title_tag[0:10]:\n",
    "# Appending the title to Job_title\n",
    "    job_title.append(i.text)\n",
    "print(job_title)\n",
    "\n",
    "# Finding the location_tag field by passing the values in the xpath\n",
    "\n",
    "location_tag=driver.find_elements_by_xpath(\"//div[@class='info fleft']//ul[@class='mt-7']//li[@class='fleft grey-text br2 placeHolderLi location']//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "\n",
    "# Initialising the job_location field\n",
    "job_location=[]\n",
    "\n",
    "#Running the for loop of first 10 values of location_tag and appending the text in the job_location field company name field\n",
    "\n",
    "for i in location_tag[0:10]:\n",
    "    job_location.append(i.text)\n",
    "print(job_location)\n",
    "\n",
    "\n",
    "# Finding the company_tag field by passing the values in the xpath\n",
    "company_tag=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "# Initialising the company name field\n",
    "company_name=[]\n",
    "\n",
    "#Running the for loop to store the first 10 values of company tag in company name field\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "print(company_name)\n",
    "\n",
    "# Finding the experience tag by passing the xpath values\n",
    "experience_tag=driver.find_elements_by_xpath(\"//ul[@class='mt-7']//li[@class='fleft grey-text br2 placeHolderLi experience']//span[@class='ellipsis fleft fs12 lh16']\")\n",
    "\n",
    "# Initialising the Experience Required field\n",
    "experience_required=[]\n",
    "\n",
    "#Running the for loop to store the first 10 values of experience tag in experience required field\n",
    "for i in experience_tag[0:10]:\n",
    "    experience_required.append(i.text)\n",
    "print(experience_required)\n",
    "\n",
    "# importing the pandas library to create a dataframe to store all the Data Analyst jobs available in \n",
    "# Delji in DS_Delhi dataframe\n",
    "import pandas as pd\n",
    "DS_Delhi=pd.DataFrame({})\n",
    "\n",
    "DS_Delhi[\"Title\"]=job_title\n",
    "DS_Delhi[\"Location\"]=job_location\n",
    "DS_Delhi[\"Company Name\"]=company_name\n",
    "DS_Delhi[\"Experience\"]=experience_required\n",
    "DS_Delhi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4:Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took too much time!\n",
      "continuing since no frame loaded this time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of the company</th>\n",
       "      <th>Days Posted</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CarbyneTech India Pvt Ltd</td>\n",
       "      <td>10d</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Globex Digital Solutions</td>\n",
       "      <td>5d</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cadent Therapeutics</td>\n",
       "      <td>24h</td>\n",
       "      <td>No Ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistan NextGen Pvt Ltd</td>\n",
       "      <td>1d</td>\n",
       "      <td>No Ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cadent Therapeutics</td>\n",
       "      <td>24h</td>\n",
       "      <td>No Ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cadent Therapeutics</td>\n",
       "      <td>24h</td>\n",
       "      <td>No Ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cambridge Technology Inc.</td>\n",
       "      <td>6d</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Whitespace Health</td>\n",
       "      <td>30d+</td>\n",
       "      <td>No Ratings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Novartis</td>\n",
       "      <td>24h</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>6d</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name of the company Days Posted     Ratings\n",
       "0  CarbyneTech India Pvt Ltd         10d         3.1\n",
       "1   Globex Digital Solutions          5d         3.4\n",
       "2        Cadent Therapeutics         24h  No Ratings\n",
       "3     Vistan NextGen Pvt Ltd          1d  No Ratings\n",
       "4        Cadent Therapeutics         24h  No Ratings\n",
       "5        Cadent Therapeutics         24h  No Ratings\n",
       "6  Cambridge Technology Inc.          6d           4\n",
       "7          Whitespace Health        30d+  No Ratings\n",
       "8                   Novartis         24h         4.1\n",
       "9                  Microsoft          6d         4.4"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the necessary libraries and Webdrivers\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "# Importing the Chrome driver from the path and starting the browser\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "# Affixing the url\n",
    "url=\"https://www.glassdoor.co.in/index.htm\"\n",
    "username='nayeemsyed@hotmail.com'\n",
    "password='Fliprobo'\n",
    "\n",
    "# In the opened Browser we are opening the necessary url by passing the url to the driver\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "try:\n",
    "    driver.find_element_by_xpath(\"//*[@id='TopNav']/nav/div/div/div[4]/div[1]/a\").click()\n",
    "except NoSuchElementException:\n",
    "    print(\"loading taking time\")\n",
    "\n",
    "driver.find_element_by_id('userEmail').send_keys(username)\n",
    "driver.find_element_by_id('userPassword').send_keys(password)\n",
    "time.sleep(3)\n",
    "driver.find_element_by_name('submit').click()\n",
    "time.sleep(2)\n",
    "\n",
    "# Finding the element to give the search input in the job field\n",
    "search_job=driver.find_element_by_id(\"sc.keyword\")\n",
    "\n",
    "# Clearing the text before entering the necessary search parameter\n",
    "search_job.clear()\n",
    "\n",
    "# The search parameter that we are going to search here \"Data Analyst\" and sending the keys to the element \"keyword\"\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# # Similarly we are finding the element by the name \"location\", clearing the search box and passing the value \"Bangalore\"\n",
    "# search_location=driver.find_element_by_name(\"location\")\n",
    "# search_location.clear()\n",
    "# search_location.send_keys(\"Delhi/NCR\")\n",
    "time.sleep(3)\n",
    "# Clicking the search button to execute the necessary search parameters\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/header/nav[1]/div/div/div/div[4]/div[3]/form/div/button').click()\n",
    "\n",
    "try:\n",
    "    myElem = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.CLASS_NAME, 'menuLinks col-6 col-sm-3 col-md-2 order-2 pb-sm')))\n",
    "    print (\"Page is ready!\")\n",
    "except TimeoutException:\n",
    "    print (\"Loading took too much time!\")\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "# Try catch statement is used because the frame element doesn't load everytime.\n",
    "try:\n",
    "    driver.find_element_by_xpath('//*[@id=\"JAModal\"]/div/div[2]/span').click()\n",
    "except NoSuchElementException as e:\n",
    "    print(\"continuing since no frame loaded this time\")\n",
    "time.sleep(2)\n",
    "\n",
    "# Creating the tags for all the necessary values to extract\n",
    "ratings=driver.find_elements_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/article/div[1]/ul/li/div[1]')\n",
    "days_tag=driver.find_elements_by_xpath(\"//div[@data-test='job-age']\")\n",
    "company_tag=driver.find_elements_by_xpath('/html/body/div[3]/div/div/div[1]/div/div[2]/section/article/div[1]/ul/li/div[2]/div/a')\n",
    "\n",
    "# Saving the text from the tags to a list\n",
    "job_rating=[]\n",
    "for i in ratings[0:10]:\n",
    "    job_rating.append(i.text)\n",
    "\n",
    "company_name=[]\n",
    "for i in company_tag[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "days_posted=[]\n",
    "for i in days_tag[0:10]:\n",
    "    days_posted.append(i.text)\n",
    "\n",
    "# creating a Dataframe to add the extracted values of a list into a Dataframe\n",
    "Glassdoor=pd.DataFrame({})\n",
    "Glassdoor[\"Name of the company\"]=company_name\n",
    "Glassdoor[\"Days Posted\"]=days_posted\n",
    "Glassdoor[\"Ratings\"]=job_rating\n",
    "Glassdoor[\"Ratings\"]=Glassdoor[\"Ratings\"].replace(\"\",\"No Ratings\")\n",
    "Glassdoor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location.\n",
    "# You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading taking time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of Salaries</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Average Salaries</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cyient</td>\n",
       "      <td>14 salaries</td>\n",
       "      <td>₹115K</td>\n",
       "      <td>₹ 10,29,318\\n/yr</td>\n",
       "      <td>₹2,014K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>10 salaries</td>\n",
       "      <td>₹1,300K</td>\n",
       "      <td>₹ 17,46,645\\n/yr</td>\n",
       "      <td>₹3,300K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quadratic Insights</td>\n",
       "      <td>9 salaries</td>\n",
       "      <td>₹355K</td>\n",
       "      <td>₹ 5,64,728\\n/yr</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Infosys</td>\n",
       "      <td>8 salaries</td>\n",
       "      <td>₹214K</td>\n",
       "      <td>₹ 5,15,962\\n/yr</td>\n",
       "      <td>₹1,772K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>7 salaries</td>\n",
       "      <td>₹900K</td>\n",
       "      <td>₹ 16,72,738\\n/yr</td>\n",
       "      <td>₹2,300K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹573K</td>\n",
       "      <td>₹ 13,00,350\\n/yr</td>\n",
       "      <td>₹1,642K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Karvy</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹445K</td>\n",
       "      <td>₹ 5,87,140\\n/yr</td>\n",
       "      <td>₹1,405K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jotter</td>\n",
       "      <td>6 salaries</td>\n",
       "      <td>₹839K</td>\n",
       "      <td>₹ 9,27,737\\n/yr</td>\n",
       "      <td>₹1,109K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optum</td>\n",
       "      <td>5 salaries</td>\n",
       "      <td>₹848K</td>\n",
       "      <td>₹ 13,11,484\\n/yr</td>\n",
       "      <td>₹1,500K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>5 salaries</td>\n",
       "      <td>₹141K</td>\n",
       "      <td>₹ 7,76,988\\n/yr</td>\n",
       "      <td>₹1,354K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Company Name No. of Salaries Minimum Salary  Average Salaries  \\\n",
       "0              Cyient     14 salaries          ₹115K  ₹ 10,29,318\\n/yr   \n",
       "1           Microsoft     10 salaries        ₹1,300K  ₹ 17,46,645\\n/yr   \n",
       "2  Quadratic Insights      9 salaries          ₹355K   ₹ 5,64,728\\n/yr   \n",
       "3             Infosys      8 salaries          ₹214K   ₹ 5,15,962\\n/yr   \n",
       "4              Amazon      7 salaries          ₹900K  ₹ 16,72,738\\n/yr   \n",
       "5           Accenture      6 salaries          ₹573K  ₹ 13,00,350\\n/yr   \n",
       "6               Karvy      6 salaries          ₹445K   ₹ 5,87,140\\n/yr   \n",
       "7              Jotter      6 salaries          ₹839K   ₹ 9,27,737\\n/yr   \n",
       "8               Optum      5 salaries          ₹848K  ₹ 13,11,484\\n/yr   \n",
       "9  Innominds Software      5 salaries          ₹141K   ₹ 7,76,988\\n/yr   \n",
       "\n",
       "  Maximum Salary  \n",
       "0        ₹2,014K  \n",
       "1        ₹3,300K  \n",
       "2        ₹1,500K  \n",
       "3        ₹1,772K  \n",
       "4        ₹2,300K  \n",
       "5        ₹1,642K  \n",
       "6        ₹1,405K  \n",
       "7        ₹1,109K  \n",
       "8        ₹1,500K  \n",
       "9        ₹1,354K  "
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# Importing the necessary libraries and Webdrivers\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "# Importing the Chrome driver from the path and starting the browser\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "# Affixing the url\n",
    "url=\"https://www.glassdoor.co.in/Salaries/index.htm\"\n",
    "username='nayeemsyed@hotmail.com'\n",
    "password='Fliprobo'\n",
    "\n",
    "# In the opened Browser we are opening the necessary url by passing the url to the driver\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "try:\n",
    "    #driver.find_element_by_xpath(\"//a[@class='track-click gd-btn-locked-transparent susiLink sign-in strong nowrap']\").click()\n",
    "    driver.find_element_by_xpath(\"//*[@id='TopNav']/nav/div/div/div[4]/div[1]/a\").click()\n",
    "except NoSuchElementException:\n",
    "    print(\"loading taking time\")\n",
    "\n",
    "# Finding the element to give the search input in the job field\n",
    "search_job=driver.find_element_by_id(\"KeywordSearch\")\n",
    "\n",
    "# Clearing the text before entering the necessary search parameter\n",
    "search_job.clear()\n",
    "\n",
    "# The search parameter that we are going to search here \"Data Scientist\" and sending the keys to the element \"keyword\"\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element_by_id('HeroSearchButton').click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "minsal_tag=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container \"]//span[1]')\n",
    "maxsal_tag=driver.find_elements_by_xpath('//div[@class=\"common__RangeBarStyle__values common__flex__justifySpaceBetween common__flex__container \"]//span[2]')\n",
    "average_tag=driver.find_elements_by_xpath('//div[@class=\"col-2 d-none d-md-flex flex-row justify-content-end\"]')\n",
    "numsalary_tag=driver.find_elements_by_xpath('//div[@class=\"d-flex\"]//div[2]/p[5]')\n",
    "comp_tag=driver.find_elements_by_xpath('//div[@class=\"d-flex\"]//div[2]/p[2]')\n",
    "\n",
    "min_salary=[]\n",
    "max_salary=[]\n",
    "average_salary=[]\n",
    "number_salary=[]\n",
    "comp_name=[]\n",
    "for i in minsal_tag[0:10]:\n",
    "    min_salary.append(i.text)\n",
    "\n",
    "for i in maxsal_tag[0:10]:\n",
    "    max_salary.append(i.text)\n",
    "\n",
    "for i in average_tag[0:10]:\n",
    "    average_salary.append(i.text)\n",
    "\n",
    "for i in numsalary_tag[0:10]:\n",
    "    number_salary.append(i.text)\n",
    "\n",
    "for i in comp_tag[0:10]:\n",
    "    comp_name.append(i.text)\n",
    "    \n",
    "import pandas as pd\n",
    "GD_salary=pd.DataFrame({})\n",
    "\n",
    "GD_salary[\"Company Name\"]=comp_name\n",
    "GD_salary[\"No. of Salaries\"]=number_salary\n",
    "\n",
    "GD_salary[\"Minimum Salary\"]=min_salary\n",
    "GD_salary[\"Average Salaries\"]=average_salary\n",
    "GD_salary[\"Maximum Salary\"]=max_salary\n",
    "\n",
    "GD_salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "#     1. Brand\n",
    "#     2. Product Description\n",
    "#     3. Price\n",
    "#     4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price of the product</th>\n",
       "      <th>Before Discount Price</th>\n",
       "      <th>Percentage off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adrenex</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (60)</td>\n",
       "      <td>₹629</td>\n",
       "      <td>₹2,999</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrenex</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (60)</td>\n",
       "      <td>₹629</td>\n",
       "      <td>₹2,999</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDA COLLECTION</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹199</td>\n",
       "      <td>₹1,300</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>₹219</td>\n",
       "      <td>₹999</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phenomenal</td>\n",
       "      <td>UV Protection, Mirrored Retro Square Sunglasse...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>₹1,999</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹181</td>\n",
       "      <td>₹1,299</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>Mirrored Round Sunglasses (53)</td>\n",
       "      <td>₹214</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Mirrored Round Sunglasses (Free...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>₹2,665</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Yumato</td>\n",
       "      <td>Polarized Sports Sunglasses (21)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>₹1,324</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Royal Son</td>\n",
       "      <td>Mirrored Aviator Sunglasses (55)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                                        Description  \\\n",
       "0             Adrenex    Polarized, UV Protection Sports Sunglasses (60)   \n",
       "1             Adrenex    Polarized, UV Protection Sports Sunglasses (60)   \n",
       "2      FDA COLLECTION  Gradient, Mirrored, UV Protection Round, Round...   \n",
       "3    shah collections  UV Protection, Polarized, Mirrored Rectangular...   \n",
       "4          Phenomenal  UV Protection, Mirrored Retro Square Sunglasse...   \n",
       "..                ...                                                ...   \n",
       "115  shah collections              UV Protection Aviator Sunglasses (53)   \n",
       "116  shah collections                     Mirrored Round Sunglasses (53)   \n",
       "117    ROZZETTA CRAFT  UV Protection, Mirrored Round Sunglasses (Free...   \n",
       "118            Yumato                   Polarized Sports Sunglasses (21)   \n",
       "119         Royal Son                   Mirrored Aviator Sunglasses (55)   \n",
       "\n",
       "    Price of the product Before Discount Price Percentage off  \n",
       "0                   ₹629                ₹2,999        79% off  \n",
       "1                   ₹629                ₹2,999        79% off  \n",
       "2                   ₹199                ₹1,300        84% off  \n",
       "3                   ₹219                  ₹999        78% off  \n",
       "4                   ₹399                ₹1,999        80% off  \n",
       "..                   ...                   ...            ...  \n",
       "115                 ₹181                ₹1,299        86% off  \n",
       "116                 ₹214                ₹1,499        85% off  \n",
       "117                 ₹404                ₹2,665        84% off  \n",
       "118                 ₹499                ₹1,324        62% off  \n",
       "119                 ₹379                ₹1,499        74% off  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "url=\"http://www.flipkart.com\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "driver.find_element_by_tag_name('body').send_keys(Keys.ESCAPE)\n",
    "time.sleep(3)\n",
    "search = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search.send_keys(\"sunglasses\")\n",
    "search.find_element_by_xpath('//button').click()\n",
    "\n",
    "FK=pd.DataFrame({})\n",
    "prod_name=[]\n",
    "prod_desc=[]\n",
    "prod_price=[]\n",
    "prod_disc=[]\n",
    "prod_percent=[]\n",
    "\n",
    "for j in range(0,3):\n",
    "    time.sleep(3)\n",
    "    prod_name_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_2WkVRV\"]')\n",
    "    prod_desc_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//a[1]')\n",
    "    #prod_desc_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//a[contains(., \"IRpwTa\")]')\n",
    "    prod_price_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_30jeq3\"]')\n",
    "    prod_disc_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_3I9_wc\"]')\n",
    "    prod_percent_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_3Ay6Sb\"]')\n",
    "    \n",
    "    for i in prod_name_tag:\n",
    "        prod_name.append(i.text)\n",
    "    \n",
    "    for i in prod_desc_tag:\n",
    "        prod_desc.append(i.text)\n",
    "\n",
    "    for i in prod_price_tag:\n",
    "        prod_price.append(i.text)\n",
    "\n",
    "    for i in prod_disc_tag:\n",
    "        prod_disc.append(i.text)\n",
    "    \n",
    "    for i in prod_percent_tag:\n",
    "        prod_percent.append(i.text)\n",
    "    k=j+2\n",
    "    next_page=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=\"+str(k)\n",
    "    driver.get(next_page)\n",
    "    time.sleep(2)\n",
    "import pandas as pd\n",
    "\n",
    "FK[\"Name\"]=prod_name\n",
    "FK[\"Description\"]=prod_desc\n",
    "FK[\"Price of the product\"]=prod_price\n",
    "FK[\"Before Discount Price\"]=prod_disc\n",
    "FK[\"Percentage off\"]=prod_percent\n",
    "FK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# \"Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value of j is :  0\n",
      "value of j is :  1\n",
      "value of j is :  2\n",
      "value of j is :  3\n",
      "value of j is :  4\n",
      "value of j is :  5\n",
      "value of j is :  6\n",
      "value of j is :  7\n",
      "value of j is :  8\n",
      "value of j is :  9\n",
      "value of j is :  10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Short Reviews</th>\n",
       "      <th>Long Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>4</td>\n",
       "      <td>Delightful</td>\n",
       "      <td>I was using iPhone 6s from a long time and I’v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Osm &amp; fabulous phone..just upgraded from iPhon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>Thanx Flipkart giving fast delivery with genui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Terrific!!! Lucky to get this phone in first l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>brilliant design I personally liked red colour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ratings       Short Reviews  \\\n",
       "0         5    Perfect product!   \n",
       "1         5       Great product   \n",
       "2         5    Perfect product!   \n",
       "3         5  Highly recommended   \n",
       "4         5    Perfect product!   \n",
       "..      ...                 ...   \n",
       "105       4          Delightful   \n",
       "106       5      Simply awesome   \n",
       "107       5              Super!   \n",
       "108       5       Great product   \n",
       "109       5              Super!   \n",
       "\n",
       "                                          Long Reviews  \n",
       "0    Amazing phone with great cameras and better ba...  \n",
       "1    Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2    It’s a must buy who is looking for an upgrade ...  \n",
       "3    iphone 11 is a very good phone to buy only if ...  \n",
       "4    Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "..                                                 ...  \n",
       "105  I was using iPhone 6s from a long time and I’v...  \n",
       "106  Osm & fabulous phone..just upgraded from iPhon...  \n",
       "107  Thanx Flipkart giving fast delivery with genui...  \n",
       "108  Terrific!!! Lucky to get this phone in first l...  \n",
       "109  brilliant design I personally liked red colour...  \n",
       "\n",
       "[110 rows x 3 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[8]/div[7]/div/a').click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#Creating a Dataframe and the list that is going to store the extracted values \n",
    "iPhone=pd.DataFrame({})\n",
    "ratings=[]\n",
    "short_review=[]\n",
    "long_review=[]\n",
    "\n",
    "for j in range(0,11):\n",
    "    print(\"value of j is : \", j)\n",
    "    time.sleep(3)\n",
    "\n",
    "    ratings_tag=driver.find_elements_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div/div/div/div/div[1]/div')\n",
    "    short_review_tag= driver.find_elements_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div/div/div/div/div[1]/p')\n",
    "    long_review_tag= driver.find_elements_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div/div/div/div/div[2]/div/div/div')\n",
    "\n",
    "\n",
    "    for i in ratings_tag[2:]:\n",
    "        ratings.append(i.text)\n",
    "    for i in short_review_tag:\n",
    "        short_review.append(i.text)\n",
    "    for i in long_review_tag:\n",
    "        long_review.append(i.text)\n",
    "#For the next page we are incrementing the value of k by adding 2 to j value since the page counter starts from 2 and then creating a \n",
    "#driver with the new url\n",
    "    k=j+2\n",
    "    next_url='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART&page='+str(k)\n",
    "    driver.get(next_url)\n",
    "        \n",
    "iPhone[\"Ratings\"]=ratings\n",
    "iPhone[\"Short Reviews\"]=short_review\n",
    "iPhone[\"Long Reviews\"]=long_review\n",
    "iPhone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "# You have to scrape 4 attributes of each sneaker :\n",
    "# 1. Brand\n",
    "# 2. Product Description\n",
    "# 3. Price\n",
    "# 4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 119\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price of the product</th>\n",
       "      <th>Percentage off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OXPEO</td>\n",
       "      <td>Colourblocked Trending Multicolor Ultralight c...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metronaut</td>\n",
       "      <td>Casuals Sneakers For Men</td>\n",
       "      <td>₹699</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹405</td>\n",
       "      <td>59% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Men 5014 Latest Collection Stylish Casual Spor...</td>\n",
       "      <td>₹240</td>\n",
       "      <td>51% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Essence</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹579</td>\n",
       "      <td>42% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Aura</td>\n",
       "      <td>Combo Pack of 3 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹754</td>\n",
       "      <td>49% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Calcados</td>\n",
       "      <td>Trendy Fashion Combo Pack of 4 Sneakers For Men</td>\n",
       "      <td>₹798</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name                                        Description  \\\n",
       "0                 OXPEO  Colourblocked Trending Multicolor Ultralight c...   \n",
       "1             Metronaut                           Casuals Sneakers For Men   \n",
       "2                Chevit  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "3   World Wear Footwear  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "4          Robbie jones     Casual Sneakers Shoes For Men Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95         Robbie jones                                   Sneakers For Men   \n",
       "96  World Wear Footwear  Men 5014 Latest Collection Stylish Casual Spor...   \n",
       "97              Essence                                   Sneakers For Men   \n",
       "98                 Aura      Combo Pack of 3 Casual Shoes Sneakers For Men   \n",
       "99             Calcados    Trendy Fashion Combo Pack of 4 Sneakers For Men   \n",
       "\n",
       "   Price of the product Percentage off  \n",
       "0                  ₹399        60% off  \n",
       "1                  ₹699        46% off  \n",
       "2                  ₹499        75% off  \n",
       "3                  ₹499        75% off  \n",
       "4                  ₹399        60% off  \n",
       "..                  ...            ...  \n",
       "95                 ₹405        59% off  \n",
       "96                 ₹240        51% off  \n",
       "97                 ₹579        42% off  \n",
       "98                 ₹754        49% off  \n",
       "99                 ₹798        60% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "url=\"http://www.flipkart.com\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "driver.find_element_by_tag_name('body').send_keys(Keys.ESCAPE)\n",
    "time.sleep(3)\n",
    "search = driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search.send_keys(\"sneakers\")\n",
    "search.find_element_by_xpath('//button').click()\n",
    "\n",
    "\n",
    "FK_sneakers=pd.DataFrame({})\n",
    "prod_name_sneakers=[]\n",
    "prod_desc_sneakers=[]\n",
    "prod_price_sneakers=[]\n",
    "prod_disc_sneakers=[]\n",
    "prod_percent_sneakers=[]\n",
    "\n",
    "# nextpage=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/span[contains(text(),'NEXT')]/a\")\n",
    "# nextpage.click()\n",
    "\n",
    "for j in range(0,3):\n",
    "    \n",
    "    time.sleep(3)\n",
    "    tag=driver.find_elements_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[2]/div/div[3]/div/div')\n",
    "    prod_name_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_2WkVRV\"]')\n",
    "    prod_desc_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//a[1]')\n",
    "    #prod_desc_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//a[contains(., \"IRpwTa\")]')\n",
    "    prod_price_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_30jeq3\"]')\n",
    "#     prod_disc_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_3I9_wc\"]')\n",
    "    prod_percent_tag=driver.find_elements_by_xpath('//div[@class=\"_2pi5LC col-12-12\"]//div[@class=\"_2B099V\"]//div[@class=\"_3Ay6Sb\"]')\n",
    "\n",
    "    for i in prod_name_tag:\n",
    "        prod_name_sneakers.append(i.text)\n",
    "    \n",
    "    for i in prod_desc_tag:\n",
    "        prod_desc_sneakers.append(i.text)\n",
    "\n",
    "    for i in prod_price_tag:\n",
    "        prod_price_sneakers.append(i.text)\n",
    "    \n",
    "    for i in prod_percent_tag:\n",
    "        prod_percent_sneakers.append(i.text)\n",
    "    k=j+2\n",
    "    next_page=\"https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off&page=\"+str(k)\n",
    "    driver.get(next_page)\n",
    "print(len(prod_name_sneakers),len(prod_desc_sneakers),len(prod_price_sneakers),len(prod_percent_sneakers))\n",
    "import pandas as pd\n",
    "\n",
    "FK_sneakers[\"Name\"]=prod_name_sneakers[0:100]\n",
    "FK_sneakers[\"Description\"]=prod_desc_sneakers[0:100]\n",
    "FK_sneakers[\"Price of the product\"]=prod_price_sneakers[0:100]\n",
    "#FK_sneakers[\"Before Discount Price\"]=prod_disc_sneakers\n",
    "FK_sneakers[\"Percentage off\"]=prod_percent_sneakers[0:100]\n",
    "FK_sneakers[0:100]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9: Go to the link - https://www.myntra.com/shoes\n",
    "# Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Running Shoes</td>\n",
       "      <td>6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Solid SKYVE MAX Sneakers</td>\n",
       "      <td>6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men REACT PHANTOM Running</td>\n",
       "      <td>7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Sneakers</td>\n",
       "      <td>10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Solid Flatform Sneakers</td>\n",
       "      <td>6839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Iconic Mix Runner Sneakers</td>\n",
       "      <td>6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>6293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Block Heels</td>\n",
       "      <td>6392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Suede Pumps</td>\n",
       "      <td>6293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Product Name             Product Description Product Price\n",
       "0                   Nike          Men Zoom Running Shoes          6399\n",
       "1                   Nike    Men Solid SKYVE MAX Sneakers          6599\n",
       "2                   Nike   PEGASUS FLYEASE Running Shoes          7999\n",
       "3                   Nike       Men REACT PHANTOM Running          7799\n",
       "4                   Nike       Men JORDAN DELTA Sneakers         10995\n",
       "..                   ...                             ...           ...\n",
       "95        Tommy Hilfiger   Women Solid Flatform Sneakers          6839\n",
       "96        Tommy Hilfiger  Men Iconic Mix Runner Sneakers          6399\n",
       "97  Heel & Buckle London             Men Leather Loafers          6293\n",
       "98  Heel & Buckle London               Women Block Heels          6392\n",
       "99  Heel & Buckle London               Women Suede Pumps          6293\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importng the libraries \n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "#Creating the webdriver and passing the url \n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "url=\" https://www.myntra.com/shoes\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Creating the tags for the filter and color and clicking on those since the path associtaed with is a checkbox\n",
    "filter_tag=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label').click()\n",
    "time.sleep(3)\n",
    "color_tag=driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label').click()\n",
    "time.sleep(3)\n",
    "\n",
    "product_name=[]\n",
    "product_desc=[]\n",
    "product_price=[]\n",
    "final_price=[]\n",
    "\n",
    "for pages in range(0,2):\n",
    "    product_name_tag=driver.find_elements_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/ul/li/a/div[2]/h3\")\n",
    "    product_desc_tag=driver.find_elements_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/ul/li/a/div[2]/h4[1]\")\n",
    "    product_price_tag=driver.find_elements_by_xpath(\"//*[@id='desktopSearchResults']/div[2]/section/ul/li/a/div[2]/div/span[1]\")\n",
    "       \n",
    "\n",
    "    for product in product_name_tag:\n",
    "        product_name.append(product.text)\n",
    "    \n",
    "    for product in product_desc_tag:\n",
    "        product_desc.append(product.text)\n",
    "\n",
    "    for j in product_price_tag:\n",
    "        product_price.append(j.text)\n",
    "# Clicking on the xpath that corelates to the next page\n",
    "    next_page=driver.find_element_by_class_name('pagination-next').click()\n",
    "    time.sleep(5)\n",
    "\n",
    "# Splitting the price at 'Rs.' and at the second instance and then stripping the other values to just get the value \n",
    "# of discounted price and not the both discounted price and striked price\n",
    "for i in product_price:\n",
    "    split_price=i.split(\"Rs.\")[1].strip()\n",
    "    final_price.append(split_price)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "Myntra=pd.DataFrame({})\n",
    "Myntra[\"Product Name\"]=product_name\n",
    "Myntra[\"Product Description\"]=product_desc\n",
    "Myntra[\"Product Price\"]=final_price\n",
    "Myntra\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Product Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Zoom Running Shoes</td>\n",
       "      <td>6399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men Solid SKYVE MAX Sneakers</td>\n",
       "      <td>6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men React Infinity Running</td>\n",
       "      <td>11099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Sneakers</td>\n",
       "      <td>10995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>PEGASUS FLYEASE Running Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Impulse Running Shoes</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Xtep</td>\n",
       "      <td>AIR MEGA Energy Ring Shoes</td>\n",
       "      <td>5949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Women Solid Flatform Sneakers</td>\n",
       "      <td>6839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Vans</td>\n",
       "      <td>Unisex Sneakers</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Product Name            Product Description Product Price\n",
       "0             Nike         Men Zoom Running Shoes          6399\n",
       "1             Nike   Men Solid SKYVE MAX Sneakers          6599\n",
       "2             Nike     Men React Infinity Running         11099\n",
       "3             Nike      Men JORDAN DELTA Sneakers         10995\n",
       "4             Nike  PEGASUS FLYEASE Running Shoes          7999\n",
       "..             ...                            ...           ...\n",
       "95    UNDER ARMOUR  Charged Impulse Running Shoes          7999\n",
       "96            Xtep     AIR MEGA Energy Ring Shoes          5949\n",
       "97            FILA             Men Solid Sneakers          7499\n",
       "98  Tommy Hilfiger  Women Solid Flatform Sneakers          6839\n",
       "99            Vans                Unisex Sneakers          6999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10: Go to webpage https://www.amazon.in/\n",
    "# Enter “Laptop” in the search field and then click the search icon.\n",
    "# Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>₹74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>₹74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>₹2,68,329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>₹95,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion x360 Core i7 8th Gen 14-inch Touch...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>₹85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch 120hz FHD Display...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>₹82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS ROG Strix G17 17.3\" FHD 120Hz Intel Core ...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>₹1,02,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>₹96,450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>₹54,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>₹75,693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name              Rating  \\\n",
       "0  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...  3.6 out of 5 stars   \n",
       "1  Lenovo IdeaPad Gaming 3i 10th Gen Intel Core i...  3.8 out of 5 stars   \n",
       "2  ASUS ZenBook Pro Duo Intel Core i9-10980HK 10t...  5.0 out of 5 stars   \n",
       "3  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...  4.3 out of 5 stars   \n",
       "4  HP Pavilion x360 Core i7 8th Gen 14-inch Touch...  4.1 out of 5 stars   \n",
       "5  Dell G3 3500 Gaming 15.6inch 120hz FHD Display...  3.7 out of 5 stars   \n",
       "6  ASUS ROG Strix G17 17.3\" FHD 120Hz Intel Core ...  4.2 out of 5 stars   \n",
       "7  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...  3.3 out of 5 stars   \n",
       "8  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.2 out of 5 stars   \n",
       "9  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...  4.2 out of 5 stars   \n",
       "\n",
       "       price  \n",
       "0    ₹74,990  \n",
       "1    ₹74,990  \n",
       "2  ₹2,68,329  \n",
       "3    ₹95,590  \n",
       "4    ₹85,990  \n",
       "5    ₹82,990  \n",
       "6  ₹1,02,990  \n",
       "7    ₹96,450  \n",
       "8    ₹54,899  \n",
       "9    ₹75,693  "
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "driver= webdriver.Chrome(r\"C:\\Users\\Home\\Downloads\\Nayeem\\FlipRobo internship\\WebSCraper\\chromedriver.exe\")\n",
    "\n",
    "url=\" https://www.amazon.in\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "search_tag=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_tag.send_keys(\"Laptop\")\n",
    "driver.find_element_by_id(\"nav-search-submit-button\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "# Creating the filter tag for Intel Core i7 and i9\n",
    "filter_tag_1=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/div/label').click()\n",
    "time.sleep(4)\n",
    "filter_tag_2=driver.find_element_by_xpath('//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/div/label').click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Creating the tags for the attributes name, rating and price\n",
    "lap_name_tag=driver.find_elements_by_xpath('//*[@id=\"search\"]/div[1]/div[2]/div/span[3]/div[2]/div/div/span/div/div/div[2]/div[2]/div/div[1]/div/div/div[1]/h2/a/span')\n",
    "lap_rating_tag=driver.find_elements_by_xpath('//*[@id=\"search\"]/div[1]/div[2]/div/span[3]/div[2]/div/div/span/div/div/div[2]/div[2]/div/div[1]/div/div/div[2]/div/span[1]/span/a/i[1]/span')\n",
    "lap_price_tag=driver.find_elements_by_xpath('//*[@id=\"search\"]/div[1]/div[2]/div/span[3]/div[2]/div/div/span/div/div/div[2]/div[2]/div/div[2]/div[1]/div/div[1]/div[1]/div/div/a/span[1]')\n",
    "\n",
    "lap_name=[]\n",
    "lap_rating=[]\n",
    "lap_price=[]\n",
    "for i in lap_rating_tag[0:10]:\n",
    "    time.sleep(1)\n",
    "#Since the value is insde the innerText attribute we have to extract the text using get_attribute method\n",
    "    if i.get_attribute(\"innerText\")==\"\":\n",
    "        lap_rating.append(\"No Rating\")\n",
    "    else:\n",
    "        lap_rating.append(i.get_attribute(\"innerText\"))\n",
    "for i in lap_name_tag[0:10]:\n",
    "    lap_name.append(i.text)\n",
    "for i in lap_price_tag[0:10]:\n",
    "    lap_price.append(i.text)\n",
    "\n",
    "import pandas as pd\n",
    "Laptop=pd.DataFrame({})\n",
    "Laptop[\"Name\"]=lap_name\n",
    "Laptop[\"Rating\"]=lap_rating\n",
    "Laptop[\"price\"]=lap_price\n",
    "Laptop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
